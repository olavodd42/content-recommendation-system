{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e144c585",
   "metadata": {},
   "source": [
    "# Desenvolvimento de Modelos de Recomenda√ß√£o\n",
    "3 abordagens: Baseline ‚Üí Collaborative Filtering ‚Üí H√≠brido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75c02174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Criar pasta para modelos\n",
    "Path('models').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21f609",
   "metadata": {},
   "source": [
    "## PREPARA√á√ÉO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c46885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìÇ PREPARANDO DADOS PARA MODELAGEM\n",
      "================================================================================\n",
      "‚úÖ 100,000 avalia√ß√µes carregadas\n",
      "\n",
      "üìä Split dos dados:\n",
      "   Treino: 80,000 avalia√ß√µes (80.0%)\n",
      "   Teste: 20,000 avalia√ß√µes (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìÇ PREPARANDO DADOS PARA MODELAGEM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv('../data/processed/ratings.csv')\n",
    "print(f\"‚úÖ {len(df):,} avalia√ß√µes carregadas\")\n",
    "\n",
    "# Split train/test (80/20)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"\\nüìä Split dos dados:\")\n",
    "print(f\"   Treino: {len(train_df):,} avalia√ß√µes ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Teste: {len(test_df):,} avalia√ß√µes ({len(test_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aebef5",
   "metadata": {},
   "source": [
    "### MODELO 1: BASELINE (M√©dia Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4526c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîπ MODELO 1: BASELINE - M√©dia Global\n",
      "================================================================================\n",
      "   M√©dia global treinada: 3.53\n",
      "\n",
      "üìä M√©tricas no teste:\n",
      "   RMSE: 1.1239\n",
      "   MAE: 0.9420\n",
      "üíæ Modelo salvo: ../models/baseline_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîπ MODELO 1: BASELINE - M√©dia Global\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class BaselineRecommender:\n",
    "    \"\"\"\n",
    "    Prediz sempre a m√©dia global dos ratings.\n",
    "    M√©todos:\n",
    "        * fit(ratings_df: pd.DataFrame) -> BaselineRecommender: Treina o modelo.\n",
    "        * predict(user_id: int, item_id: int) -> float: Prediz a avalia√ß√£o para um par usu√°rio-item.\n",
    "        * evaluate(test_df: pd.DataFrame) -> dict: Avalia o modelo usando RMSE e MAE.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.global_mean = None\n",
    "    \n",
    "    def fit(self, ratings_df: pd.DataFrame) -> 'BaselineRecommender':\n",
    "        \"\"\"\n",
    "        Treina o modelo calculando a m√©dia global dos ratings.\n",
    "        Par√¢metros:\n",
    "            * ratings_df: pd.DataFrame -> DataFrame contendo as avalia√ß√µes com colunas ['user_id', 'item_id', 'rating'].\n",
    "        Retorna:\n",
    "            * self: BaselineRecommender -> Inst√¢ncia do modelo treinado.\n",
    "        \"\"\"\n",
    "\n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        print(f\"   M√©dia global treinada: {self.global_mean:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Prediz a avalia√ß√£o para um par usu√°rio-item.\n",
    "        Par√¢metros:\n",
    "            * user_id: int -> ID do usu√°rio.\n",
    "            * item_id: int -> ID do item.\n",
    "        Retorna:\n",
    "            * float -> Avalia√ß√£o predita (m√©dia global).\n",
    "        \"\"\"\n",
    "\n",
    "        return self.global_mean\n",
    "    \n",
    "    def evaluate(self, test_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Avalia o modelo usando RMSE e MAE.\n",
    "        Par√¢metros:\n",
    "            * test_df: pd.DataFrame -> DataFrame de teste com colunas ['user_id', 'item_id', 'rating'].\n",
    "        Retorna:\n",
    "            * dict -> Dicion√°rio com m√©tricas {'RMSE': float, 'MAE': float}.\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = [self.predict(row['user_id'], row['item_id']) \n",
    "                      for _, row in test_df.iterrows()]\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(test_df['rating'], predictions))\n",
    "        mae = mean_absolute_error(test_df['rating'], predictions)\n",
    "        \n",
    "        return {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Treinar baseline\n",
    "baseline_model = BaselineRecommender()\n",
    "baseline_model.fit(train_df)\n",
    "\n",
    "# Avaliar\n",
    "baseline_metrics = baseline_model.evaluate(test_df)\n",
    "print(f\"\\nüìä M√©tricas no teste:\")\n",
    "print(f\"   RMSE: {baseline_metrics['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {baseline_metrics['MAE']:.4f}\")\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../models/baseline_model.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_model, f)\n",
    "print(\"üíæ Modelo salvo: ../models/baseline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347dd08",
   "metadata": {},
   "source": [
    "### MODELO 2: USER-BASED COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c4661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîπ MODELO 2: USER-BASED COLLABORATIVE FILTERING\n",
      "================================================================================\n",
      "   Criando matriz usu√°rio-item...\n",
      "   Calculando similaridade entre usu√°rios...\n",
      "   ‚úÖ Matriz: (943, 1653) | K-vizinhos: 30\n",
      "   üìä M√©dia global: 3.53\n",
      "   Avaliando modelo no conjunto de teste...\n",
      "      Progresso: 70000/20000 predi√ß√µes\n",
      "      Progresso: 10000/20000 predi√ß√µes\n",
      "      Progresso: 25000/20000 predi√ß√µes\n",
      "      Progresso: 100000/20000 predi√ß√µes\n",
      "\n",
      "   üîç Diagn√≥stico das predi√ß√µes:\n",
      "      Predi√ß√µes inv√°lidas: 0 (0.00%)\n",
      "      Predi√ß√µes m√≠nima: 1.00\n",
      "      Predi√ß√µes m√°xima: 4.95\n",
      "      Predi√ß√µes m√©dia: 3.52\n",
      "      Predi√ß√µes std: 0.58\n",
      "\n",
      "üìä M√©tricas no teste:\n",
      "   RMSE: 0.9953\n",
      "   MAE: 0.7900\n",
      "\n",
      "üìà Melhoria sobre baseline:\n",
      "   RMSE: +11.44%\n",
      "   MAE: +16.13%\n",
      "üíæ Modelo salvo: ../models/collaborative_filtering_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîπ MODELO 2: USER-BASED COLLABORATIVE FILTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class UserBasedCF:\n",
    "    \"\"\"\n",
    "    Collaborative Filtering baseado em similaridade de usu√°rios.\n",
    "    \n",
    "    CORRE√á√ïES IMPLEMENTADAS:\n",
    "    - Valida√ß√£o de valores NaN/Inf em todas as predi√ß√µes\n",
    "    - Fallback robusto para casos extremos\n",
    "    - Logging de predi√ß√µes problem√°ticas\n",
    "    - Normaliza√ß√£o correta dos ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k_neighbors: int = 20, min_neighbors: int = 3):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.min_neighbors = min_neighbors  # M√≠nimo de vizinhos para confiar na predi√ß√£o\n",
    "        self.user_item_matrix = None\n",
    "        self.user_similarity = None\n",
    "        self.user_mean = None\n",
    "        self.global_mean = None\n",
    "        self.problem_predictions = []  # Para debug\n",
    "    \n",
    "    def fit(self, ratings_df: pd.DataFrame) -> 'UserBasedCF':\n",
    "        \"\"\"Treina o modelo com valida√ß√µes adicionais\"\"\"\n",
    "        \n",
    "        print(\"   Criando matriz usu√°rio-item...\")\n",
    "        self.user_item_matrix = ratings_df.pivot_table(\n",
    "            index='user_id',\n",
    "            columns='item_id',\n",
    "            values='rating'\n",
    "        )\n",
    "        \n",
    "        # Calcular m√©dias (IMPORTANTE: com valida√ß√£o)\n",
    "        self.user_mean = self.user_item_matrix.mean(axis=1)\n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        \n",
    "        # Verificar se h√° NaN nas m√©dias\n",
    "        if self.user_mean.isna().any():\n",
    "            print(f\"   ‚ö†Ô∏è {self.user_mean.isna().sum()} usu√°rios sem m√©dia v√°lida\")\n",
    "            self.user_mean = self.user_mean.fillna(self.global_mean)\n",
    "        \n",
    "        # Normalizar ratings (subtrair m√©dia do usu√°rio)\n",
    "        user_item_normalized = self.user_item_matrix.sub(self.user_mean, axis=0).fillna(0)\n",
    "        \n",
    "        print(\"   Calculando similaridade entre usu√°rios...\")\n",
    "        self.user_similarity = cosine_similarity(user_item_normalized)\n",
    "        \n",
    "        # Verificar se h√° NaN/Inf na matriz de similaridade\n",
    "        if np.isnan(self.user_similarity).any() or np.isinf(self.user_similarity).any():\n",
    "            print(\"   ‚ö†Ô∏è Similaridades inv√°lidas detectadas, corrigindo...\")\n",
    "            self.user_similarity = np.nan_to_num(self.user_similarity, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "        \n",
    "        print(f\"   ‚úÖ Matriz: {self.user_item_matrix.shape} | K-vizinhos: {self.k_neighbors}\")\n",
    "        print(f\"   üìä M√©dia global: {self.global_mean:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"Prediz rating com valida√ß√µes robustas\"\"\"\n",
    "        \n",
    "        # CASO 1: Usu√°rio ou item n√£o existe ‚Üí m√©dia global\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return self.global_mean\n",
    "        \n",
    "        if item_id not in self.user_item_matrix.columns:\n",
    "            return self.user_mean[user_id]\n",
    "        \n",
    "        # CASO 2: Usu√°rio j√° avaliou o item ‚Üí retornar rating conhecido\n",
    "        user_rating = self.user_item_matrix.loc[user_id, item_id]\n",
    "        if not np.isnan(user_rating):\n",
    "            return float(user_rating)\n",
    "        \n",
    "        # CASO 3: Fazer predi√ß√£o baseada em vizinhos\n",
    "        try:\n",
    "            user_idx = self.user_item_matrix.index.get_loc(user_id)\n",
    "            similarities = self.user_similarity[user_idx]\n",
    "            \n",
    "            # Pegar ratings dos vizinhos para este item\n",
    "            item_ratings = self.user_item_matrix[item_id]\n",
    "            rated_users_mask = ~item_ratings.isna()\n",
    "            \n",
    "            # Se ningu√©m avaliou este item ‚Üí m√©dia do usu√°rio\n",
    "            if rated_users_mask.sum() == 0:\n",
    "                return self.user_mean[user_id]\n",
    "            \n",
    "            neighbor_ratings = item_ratings[rated_users_mask]\n",
    "            neighbor_similarities = similarities[rated_users_mask]\n",
    "            \n",
    "            # Remover similaridades negativas ou zero\n",
    "            positive_mask = neighbor_similarities > 0\n",
    "            if positive_mask.sum() < self.min_neighbors:\n",
    "                # Poucos vizinhos confi√°veis ‚Üí usar m√©dia do usu√°rio\n",
    "                return self.user_mean[user_id]\n",
    "            \n",
    "            neighbor_ratings = neighbor_ratings[positive_mask]\n",
    "            neighbor_similarities = neighbor_similarities[positive_mask]\n",
    "            \n",
    "            # Pegar top-k vizinhos\n",
    "            if len(neighbor_similarities) > self.k_neighbors:\n",
    "                top_k_idx = np.argsort(neighbor_similarities)[-self.k_neighbors:]\n",
    "                neighbor_ratings = neighbor_ratings.iloc[top_k_idx]\n",
    "                neighbor_similarities = neighbor_similarities[top_k_idx]\n",
    "            \n",
    "            # Calcular predi√ß√£o ponderada\n",
    "            total_similarity = neighbor_similarities.sum()\n",
    "            \n",
    "            if total_similarity == 0:\n",
    "                prediction = self.user_mean[user_id]\n",
    "            else:\n",
    "                prediction = np.average(neighbor_ratings, weights=neighbor_similarities)\n",
    "            \n",
    "            # VALIDA√á√ÉO FINAL: Verificar se predi√ß√£o √© v√°lida\n",
    "            if np.isnan(prediction) or np.isinf(prediction):\n",
    "                self.problem_predictions.append({\n",
    "                    'user_id': user_id,\n",
    "                    'item_id': item_id,\n",
    "                    'prediction': prediction,\n",
    "                    'fallback': self.user_mean[user_id]\n",
    "                })\n",
    "                return self.user_mean[user_id]\n",
    "            \n",
    "            # Limitar predi√ß√£o ao range v√°lido (ex: 1-5 para MovieLens)\n",
    "            min_rating = 1.0\n",
    "            max_rating = 5.0\n",
    "            prediction = np.clip(prediction, min_rating, max_rating)\n",
    "            \n",
    "            return float(prediction)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Qualquer erro ‚Üí fallback seguro\n",
    "            print(f\"   ‚ö†Ô∏è Erro na predi√ß√£o: {e}\")\n",
    "            return self.user_mean[user_id]\n",
    "    \n",
    "    def recommend(self, user_id: int, n: int = 5) -> list[int]:\n",
    "        \"\"\"Retorna top-N recomenda√ß√µes\"\"\"\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return []\n",
    "        \n",
    "        user_ratings = self.user_item_matrix.loc[user_id]\n",
    "        unrated_items = user_ratings[user_ratings.isna()].index\n",
    "        \n",
    "        predictions = []\n",
    "        for item_id in unrated_items:\n",
    "            pred_rating = self.predict(user_id, item_id)\n",
    "            predictions.append((item_id, pred_rating))\n",
    "        \n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [item_id for item_id, _ in predictions[:n]]\n",
    "    \n",
    "    def evaluate(self, test_df: pd.DataFrame, verbose: bool = True) -> dict:\n",
    "        \"\"\"Avalia modelo com diagn√≥stico detalhado\"\"\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"   Avaliando modelo no conjunto de teste...\")\n",
    "        \n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        invalid_count = 0\n",
    "        \n",
    "        for idx, row in test_df.iterrows():\n",
    "            pred = self.predict(row['user_id'], row['item_id'])\n",
    "            \n",
    "            # Verificar validade da predi√ß√£o\n",
    "            if np.isnan(pred) or np.isinf(pred):\n",
    "                invalid_count += 1\n",
    "                pred = self.global_mean\n",
    "            \n",
    "            predictions.append(pred)\n",
    "            actuals.append(row['rating'])\n",
    "            \n",
    "            if verbose and (idx + 1) % 5000 == 0:\n",
    "                print(f\"      Progresso: {idx+1}/{len(test_df)} predi√ß√µes\")\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        \n",
    "        # Diagn√≥stico adicional\n",
    "        predictions_array = np.array(predictions)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n   üîç Diagn√≥stico das predi√ß√µes:\")\n",
    "            print(f\"      Predi√ß√µes inv√°lidas: {invalid_count} ({invalid_count/len(predictions)*100:.2f}%)\")\n",
    "            print(f\"      Predi√ß√µes m√≠nima: {predictions_array.min():.2f}\")\n",
    "            print(f\"      Predi√ß√µes m√°xima: {predictions_array.max():.2f}\")\n",
    "            print(f\"      Predi√ß√µes m√©dia: {predictions_array.mean():.2f}\")\n",
    "            print(f\"      Predi√ß√µes std: {predictions_array.std():.2f}\")\n",
    "        \n",
    "        return {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'invalid_predictions': invalid_count,\n",
    "            'predictions_stats': {\n",
    "                'min': float(predictions_array.min()),\n",
    "                'max': float(predictions_array.max()),\n",
    "                'mean': float(predictions_array.mean()),\n",
    "                'std': float(predictions_array.std())\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Treinar modelo\n",
    "cf_model = UserBasedCF(k_neighbors=30)\n",
    "cf_model.fit(train_df)\n",
    "\n",
    "# Avaliar\n",
    "cf_metrics = cf_model.evaluate(test_df)\n",
    "print(f\"\\nüìä M√©tricas no teste:\")\n",
    "print(f\"   RMSE: {cf_metrics['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {cf_metrics['MAE']:.4f}\")\n",
    "\n",
    "# Compara√ß√£o com baseline\n",
    "print(f\"\\nüìà Melhoria sobre baseline:\")\n",
    "print(f\"   RMSE: {(1 - cf_metrics['RMSE']/baseline_metrics['RMSE'])*100:+.2f}%\")\n",
    "print(f\"   MAE: {(1 - cf_metrics['MAE']/baseline_metrics['MAE'])*100:+.2f}%\")\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../models/collaborative_filtering_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cf_model, f)\n",
    "print(\"üíæ Modelo salvo: ../models/collaborative_filtering_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257a570",
   "metadata": {},
   "source": [
    "#### TESTE PR√ÅTICO: GERAR RECOMENDA√á√ïES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3cd5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ TESTE PR√ÅTICO DE RECOMENDA√á√ïES\n",
      "================================================================================\n",
      "\n",
      "üë§ Testando recomenda√ß√µes para usu√°rio 416:\n",
      "\n",
      "üìú Hist√≥rico (top 10 ratings):\n",
      " item_id  rating\n",
      "     213       5\n",
      "     684       5\n",
      "      65       5\n",
      "     471       5\n",
      "     385       5\n",
      "    1007       5\n",
      "     121       5\n",
      "       8       5\n",
      "      83       5\n",
      "     531       5\n",
      "\n",
      "‚≠ê Top 10 recomenda√ß√µes:\n",
      "   1. Item 1125 (rating estimado: 4.81)\n",
      "   2. Item 113 (rating estimado: 4.78)\n",
      "   3. Item 12 (rating estimado: 4.63)\n",
      "   4. Item 114 (rating estimado: 4.61)\n",
      "   5. Item 50 (rating estimado: 4.54)\n",
      "   6. Item 313 (rating estimado: 4.52)\n",
      "   7. Item 1449 (rating estimado: 4.51)\n",
      "   8. Item 963 (rating estimado: 4.49)\n",
      "   9. Item 170 (rating estimado: 4.43)\n",
      "   10. Item 1514 (rating estimado: 4.41)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ TESTE PR√ÅTICO DE RECOMENDA√á√ïES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Escolher um usu√°rio de teste\n",
    "test_user = train_df['user_id'].value_counts().index[5]  # 6¬∫ usu√°rio mais ativo\n",
    "print(f\"\\nüë§ Testando recomenda√ß√µes para usu√°rio {test_user}:\")\n",
    "\n",
    "# Ver hist√≥rico do usu√°rio\n",
    "user_history = train_df[train_df['user_id'] == test_user].sort_values('rating', ascending=False)\n",
    "print(f\"\\nüìú Hist√≥rico (top 10 ratings):\")\n",
    "print(user_history.head(10)[['item_id', 'rating']].to_string(index=False))\n",
    "\n",
    "# Gerar recomenda√ß√µes\n",
    "recommendations = cf_model.recommend(test_user, n=10)\n",
    "print(f\"\\n‚≠ê Top 10 recomenda√ß√µes:\")\n",
    "for i, item_id in enumerate(recommendations, 1):\n",
    "    pred_rating = cf_model.predict(test_user, item_id)\n",
    "    print(f\"   {i}. Item {item_id} (rating estimado: {pred_rating:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa30e98",
   "metadata": {},
   "source": [
    "### MODELO 3: ITEM-BASED COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c973c5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîπ MODELO 3: ITEM-BASED COLLABORATIVE FILTERING\n",
      "================================================================================\n",
      "   Criando matriz item-usu√°rio...\n",
      "   Calculando similaridade entre itens...\n",
      "   ‚úÖ 1653 itens processados\n",
      "   Avaliando modelo item-based...\n",
      "      Progresso: 70000/20000\n",
      "      Progresso: 10000/20000\n",
      "      Progresso: 25000/20000\n",
      "      Progresso: 100000/20000\n",
      "\n",
      "üìä M√©tricas no teste:\n",
      "   RMSE: 0.9757\n",
      "   MAE: 0.7649\n",
      "üíæ Modelo salvo: models/item_based_cf_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîπ MODELO 3: ITEM-BASED COLLABORATIVE FILTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class ItemBasedCF:\n",
    "    \"\"\"Collaborative Filtering baseado em similaridade de itens\"\"\"\n",
    "    \n",
    "    def __init__(self, k_neighbors=20):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.item_similarity = None\n",
    "        self.user_item_matrix = None\n",
    "    \n",
    "    def fit(self, ratings_df):\n",
    "        print(\"   Criando matriz item-usu√°rio...\")\n",
    "        # Transpor para ter itens nas linhas\n",
    "        self.user_item_matrix = ratings_df.pivot_table(\n",
    "            index='user_id',\n",
    "            columns='item_id',\n",
    "            values='rating'\n",
    "        )\n",
    "        \n",
    "        item_user_matrix = self.user_item_matrix.T.fillna(0)\n",
    "        \n",
    "        print(\"   Calculando similaridade entre itens...\")\n",
    "        self.item_similarity = cosine_similarity(item_user_matrix)\n",
    "        \n",
    "        print(f\"   ‚úÖ {len(item_user_matrix)} itens processados\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        if user_id not in self.user_item_matrix.index or \\\n",
    "           item_id not in self.user_item_matrix.columns:\n",
    "            return self.user_item_matrix.mean().mean()\n",
    "        \n",
    "        # Itens que o usu√°rio avaliou\n",
    "        user_ratings = self.user_item_matrix.loc[user_id]\n",
    "        rated_items = user_ratings[~user_ratings.isna()]\n",
    "        \n",
    "        if len(rated_items) == 0:\n",
    "            return self.user_item_matrix.mean().mean()\n",
    "        \n",
    "        # Similaridades do item target com itens avaliados\n",
    "        item_idx = self.user_item_matrix.columns.get_loc(item_id)\n",
    "        similarities = []\n",
    "        ratings = []\n",
    "        \n",
    "        for rated_item_id in rated_items.index:\n",
    "            rated_item_idx = self.user_item_matrix.columns.get_loc(rated_item_id)\n",
    "            sim = self.item_similarity[item_idx, rated_item_idx]\n",
    "            \n",
    "            if sim > 0:\n",
    "                similarities.append(sim)\n",
    "                ratings.append(rated_items[rated_item_id])\n",
    "        \n",
    "        if len(similarities) == 0:\n",
    "            return self.user_item_matrix[item_id].mean()\n",
    "        \n",
    "        # Top-k itens similares\n",
    "        if len(similarities) > self.k_neighbors:\n",
    "            top_k_idx = np.argsort(similarities)[-self.k_neighbors:]\n",
    "            similarities = [similarities[i] for i in top_k_idx]\n",
    "            ratings = [ratings[i] for i in top_k_idx]\n",
    "        \n",
    "        # Predi√ß√£o ponderada\n",
    "        prediction = np.average(ratings, weights=similarities)\n",
    "        return prediction\n",
    "    \n",
    "    def evaluate(self, test_df):\n",
    "        print(\"   Avaliando modelo item-based...\")\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        for idx, row in test_df.iterrows():\n",
    "            pred = self.predict(row['user_id'], row['item_id'])\n",
    "            predictions.append(pred)\n",
    "            actuals.append(row['rating'])\n",
    "            \n",
    "            if (idx + 1) % 5000 == 0:\n",
    "                print(f\"      Progresso: {idx+1}/{len(test_df)}\")\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        \n",
    "        return {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Treinar modelo item-based\n",
    "item_cf_model = ItemBasedCF(k_neighbors=30)\n",
    "item_cf_model.fit(train_df)\n",
    "\n",
    "# Avaliar\n",
    "item_cf_metrics = item_cf_model.evaluate(test_df)\n",
    "print(f\"\\nüìä M√©tricas no teste:\")\n",
    "print(f\"   RMSE: {item_cf_metrics['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {item_cf_metrics['MAE']:.4f}\")\n",
    "\n",
    "# Salvar modelo\n",
    "with open('models/item_based_cf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(item_cf_model, f)\n",
    "print(\"üíæ Modelo salvo: models/item_based_cf_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867a77ff",
   "metadata": {},
   "source": [
    "#### COMPARA√á√ÉO FINAL DOS MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f98c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üèÜ COMPARA√á√ÉO FINAL DOS MODELOS\n",
      "================================================================================\n",
      "\n",
      "       Modelo     RMSE      MAE\n",
      "     Baseline 1.123860 0.941955\n",
      "User-Based CF 0.995258 0.789983\n",
      "Item-Based CF 0.975689 0.764899\n",
      "\n",
      "ü•á Melhor modelo: Item-Based CF\n",
      "   RMSE: 0.9757\n",
      "   MAE: 0.7649\n",
      "\n",
      "üíæ Resultados salvos: docs/model_comparison.csv\n",
      "\n",
      "================================================================================\n",
      "‚úÖ DESENVOLVIMENTO DE MODELOS CONCLU√çDO!\n",
      "================================================================================\n",
      "\n",
      "Pr√≥ximos passos:\n",
      "   1. Criar m√≥dulo de produ√ß√£o (src/models/recommender.py)\n",
      "   2. Desenvolver API FastAPI\n",
      "   3. Implementar testes unit√°rios\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üèÜ COMPARA√á√ÉO FINAL DOS MODELOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Modelo': ['Baseline', 'User-Based CF', 'Item-Based CF'],\n",
    "    'RMSE': [baseline_metrics['RMSE'], cf_metrics['RMSE'], item_cf_metrics['RMSE']],\n",
    "    'MAE': [baseline_metrics['MAE'], cf_metrics['MAE'], item_cf_metrics['MAE']]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + results.to_string(index=False))\n",
    "\n",
    "# Melhor modelo\n",
    "best_model_idx = results['RMSE'].idxmin()\n",
    "best_model_name = results.loc[best_model_idx, 'Modelo']\n",
    "print(f\"\\nü•á Melhor modelo: {best_model_name}\")\n",
    "print(f\"   RMSE: {results.loc[best_model_idx, 'RMSE']:.4f}\")\n",
    "print(f\"   MAE: {results.loc[best_model_idx, 'MAE']:.4f}\")\n",
    "\n",
    "# Salvar resultados\n",
    "results.to_csv('../docs/model_comparison.csv', index=False)\n",
    "print(\"\\nüíæ Resultados salvos: docs/model_comparison.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ DESENVOLVIMENTO DE MODELOS CONCLU√çDO!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nPr√≥ximos passos:\")\n",
    "print(\"   1. Criar m√≥dulo de produ√ß√£o (src/models/recommender.py)\")\n",
    "print(\"   2. Desenvolver API FastAPI\")\n",
    "print(\"   3. Implementar testes unit√°rios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed669be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
