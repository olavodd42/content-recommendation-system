{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e144c585",
   "metadata": {},
   "source": [
    "# Desenvolvimento de Modelos de Recomenda√ß√£o\n",
    "3 abordagens: Baseline ‚Üí Collaborative Filtering ‚Üí H√≠brido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c02174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Criar pasta para modelos\n",
    "Path('models').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21f609",
   "metadata": {},
   "source": [
    "## PREPARA√á√ÉO DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c46885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìÇ PREPARANDO DADOS PARA MODELAGEM\n",
      "================================================================================\n",
      "‚úÖ 100,000 avalia√ß√µes carregadas\n",
      "\n",
      "üìä Split dos dados:\n",
      "   Treino: 80,000 avalia√ß√µes (80.0%)\n",
      "   Teste: 20,000 avalia√ß√µes (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìÇ PREPARANDO DADOS PARA MODELAGEM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Carregar dados\n",
    "df = pd.read_csv('../data/processed/ratings.csv')\n",
    "print(f\"‚úÖ {len(df):,} avalia√ß√µes carregadas\")\n",
    "\n",
    "# Split train/test (80/20)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "print(f\"\\nüìä Split dos dados:\")\n",
    "print(f\"   Treino: {len(train_df):,} avalia√ß√µes ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Teste: {len(test_df):,} avalia√ß√µes ({len(test_df)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aebef5",
   "metadata": {},
   "source": [
    "### MODELO 1: BASELINE (M√©dia Global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4526c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîπ MODELO 1: BASELINE - M√©dia Global\n",
      "================================================================================\n",
      "   M√©dia global treinada: 3.53\n",
      "\n",
      "üìä M√©tricas no teste:\n",
      "   RMSE: 1.1239\n",
      "   MAE: 0.9420\n",
      "üíæ Modelo salvo: ../models/baseline_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîπ MODELO 1: BASELINE - M√©dia Global\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class BaselineRecommender:\n",
    "    \"\"\"\n",
    "    Prediz sempre a m√©dia global dos ratings.\n",
    "    M√©todos:\n",
    "        * fit(ratings_df: pd.DataFrame) -> BaselineRecommender: Treina o modelo.\n",
    "        * predict(user_id: int, item_id: int) -> float: Prediz a avalia√ß√£o para um par usu√°rio-item.\n",
    "        * evaluate(test_df: pd.DataFrame) -> dict: Avalia o modelo usando RMSE e MAE.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.global_mean = None\n",
    "    \n",
    "    def fit(self, ratings_df: pd.DataFrame) -> 'BaselineRecommender':\n",
    "        \"\"\"\n",
    "        Treina o modelo calculando a m√©dia global dos ratings.\n",
    "        Par√¢metros:\n",
    "            * ratings_df: pd.DataFrame -> DataFrame contendo as avalia√ß√µes com colunas ['user_id', 'item_id', 'rating'].\n",
    "        Retorna:\n",
    "            * self: BaselineRecommender -> Inst√¢ncia do modelo treinado.\n",
    "        \"\"\"\n",
    "\n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        print(f\"   M√©dia global treinada: {self.global_mean:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"\n",
    "        Prediz a avalia√ß√£o para um par usu√°rio-item.\n",
    "        Par√¢metros:\n",
    "            * user_id: int -> ID do usu√°rio.\n",
    "            * item_id: int -> ID do item.\n",
    "        Retorna:\n",
    "            * float -> Avalia√ß√£o predita (m√©dia global).\n",
    "        \"\"\"\n",
    "\n",
    "        return self.global_mean\n",
    "    \n",
    "    def evaluate(self, test_df: pd.DataFrame) -> dict:\n",
    "        \"\"\"\n",
    "        Avalia o modelo usando RMSE e MAE.\n",
    "        Par√¢metros:\n",
    "            * test_df: pd.DataFrame -> DataFrame de teste com colunas ['user_id', 'item_id', 'rating'].\n",
    "        Retorna:\n",
    "            * dict -> Dicion√°rio com m√©tricas {'RMSE': float, 'MAE': float}.\n",
    "        \"\"\"\n",
    "        \n",
    "        predictions = [self.predict(row['user_id'], row['item_id']) \n",
    "                      for _, row in test_df.iterrows()]\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(test_df['rating'], predictions))\n",
    "        mae = mean_absolute_error(test_df['rating'], predictions)\n",
    "        \n",
    "        return {'RMSE': rmse, 'MAE': mae}\n",
    "\n",
    "# Treinar baseline\n",
    "baseline_model = BaselineRecommender()\n",
    "baseline_model.fit(train_df)\n",
    "\n",
    "# Avaliar\n",
    "baseline_metrics = baseline_model.evaluate(test_df)\n",
    "print(f\"\\nüìä M√©tricas no teste:\")\n",
    "print(f\"   RMSE: {baseline_metrics['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {baseline_metrics['MAE']:.4f}\")\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../models/baseline_model.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline_model, f)\n",
    "print(\"üíæ Modelo salvo: ../models/baseline_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b347dd08",
   "metadata": {},
   "source": [
    "### MODELO 2: USER-BASED COLLABORATIVE FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c4661c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîπ MODELO 2: USER-BASED COLLABORATIVE FILTERING\n",
      "================================================================================\n",
      "   Criando matriz usu√°rio-item...\n",
      "   Calculando similaridade entre usu√°rios...\n",
      "   ‚úÖ Matriz: (943, 1653) | K-vizinhos: 30\n",
      "   üìä M√©dia global: 3.53\n",
      "   Avaliando modelo no conjunto de teste...\n",
      "      Progresso: 70000/20000 predi√ß√µes\n",
      "      Progresso: 10000/20000 predi√ß√µes\n",
      "      Progresso: 25000/20000 predi√ß√µes\n",
      "      Progresso: 100000/20000 predi√ß√µes\n",
      "\n",
      "   üîç Diagn√≥stico das predi√ß√µes:\n",
      "      Predi√ß√µes inv√°lidas: 0 (0.00%)\n",
      "      Predi√ß√µes m√≠nima: 1.00\n",
      "      Predi√ß√µes m√°xima: 4.95\n",
      "      Predi√ß√µes m√©dia: 3.52\n",
      "      Predi√ß√µes std: 0.58\n",
      "\n",
      "üìä M√©tricas no teste:\n",
      "   RMSE: 0.9953\n",
      "   MAE: 0.7900\n",
      "\n",
      "üìà Melhoria sobre baseline:\n",
      "   RMSE: +11.44%\n",
      "   MAE: +16.13%\n",
      "üíæ Modelo salvo: ../models/collaborative_filtering_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîπ MODELO 2: USER-BASED COLLABORATIVE FILTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class UserBasedCF:\n",
    "    \"\"\"\n",
    "    Collaborative Filtering baseado em similaridade de usu√°rios.\n",
    "    \n",
    "    CORRE√á√ïES IMPLEMENTADAS:\n",
    "    - Valida√ß√£o de valores NaN/Inf em todas as predi√ß√µes\n",
    "    - Fallback robusto para casos extremos\n",
    "    - Logging de predi√ß√µes problem√°ticas\n",
    "    - Normaliza√ß√£o correta dos ratings\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k_neighbors: int = 20, min_neighbors: int = 3):\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.min_neighbors = min_neighbors  # M√≠nimo de vizinhos para confiar na predi√ß√£o\n",
    "        self.user_item_matrix = None\n",
    "        self.user_similarity = None\n",
    "        self.user_mean = None\n",
    "        self.global_mean = None\n",
    "        self.problem_predictions = []  # Para debug\n",
    "    \n",
    "    def fit(self, ratings_df: pd.DataFrame) -> 'UserBasedCF':\n",
    "        \"\"\"Treina o modelo com valida√ß√µes adicionais\"\"\"\n",
    "        \n",
    "        print(\"   Criando matriz usu√°rio-item...\")\n",
    "        self.user_item_matrix = ratings_df.pivot_table(\n",
    "            index='user_id',\n",
    "            columns='item_id',\n",
    "            values='rating'\n",
    "        )\n",
    "        \n",
    "        # Calcular m√©dias (IMPORTANTE: com valida√ß√£o)\n",
    "        self.user_mean = self.user_item_matrix.mean(axis=1)\n",
    "        self.global_mean = ratings_df['rating'].mean()\n",
    "        \n",
    "        # Verificar se h√° NaN nas m√©dias\n",
    "        if self.user_mean.isna().any():\n",
    "            print(f\"   ‚ö†Ô∏è {self.user_mean.isna().sum()} usu√°rios sem m√©dia v√°lida\")\n",
    "            self.user_mean = self.user_mean.fillna(self.global_mean)\n",
    "        \n",
    "        # Normalizar ratings (subtrair m√©dia do usu√°rio)\n",
    "        user_item_normalized = self.user_item_matrix.sub(self.user_mean, axis=0).fillna(0)\n",
    "        \n",
    "        print(\"   Calculando similaridade entre usu√°rios...\")\n",
    "        self.user_similarity = cosine_similarity(user_item_normalized)\n",
    "        \n",
    "        # Verificar se h√° NaN/Inf na matriz de similaridade\n",
    "        if np.isnan(self.user_similarity).any() or np.isinf(self.user_similarity).any():\n",
    "            print(\"   ‚ö†Ô∏è Similaridades inv√°lidas detectadas, corrigindo...\")\n",
    "            self.user_similarity = np.nan_to_num(self.user_similarity, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "        \n",
    "        print(f\"   ‚úÖ Matriz: {self.user_item_matrix.shape} | K-vizinhos: {self.k_neighbors}\")\n",
    "        print(f\"   üìä M√©dia global: {self.global_mean:.2f}\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, user_id: int, item_id: int) -> float:\n",
    "        \"\"\"Prediz rating com valida√ß√µes robustas\"\"\"\n",
    "        \n",
    "        # CASO 1: Usu√°rio ou item n√£o existe ‚Üí m√©dia global\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return self.global_mean\n",
    "        \n",
    "        if item_id not in self.user_item_matrix.columns:\n",
    "            return self.user_mean[user_id]\n",
    "        \n",
    "        # CASO 2: Usu√°rio j√° avaliou o item ‚Üí retornar rating conhecido\n",
    "        user_rating = self.user_item_matrix.loc[user_id, item_id]\n",
    "        if not np.isnan(user_rating):\n",
    "            return float(user_rating)\n",
    "        \n",
    "        # CASO 3: Fazer predi√ß√£o baseada em vizinhos\n",
    "        try:\n",
    "            user_idx = self.user_item_matrix.index.get_loc(user_id)\n",
    "            similarities = self.user_similarity[user_idx]\n",
    "            \n",
    "            # Pegar ratings dos vizinhos para este item\n",
    "            item_ratings = self.user_item_matrix[item_id]\n",
    "            rated_users_mask = ~item_ratings.isna()\n",
    "            \n",
    "            # Se ningu√©m avaliou este item ‚Üí m√©dia do usu√°rio\n",
    "            if rated_users_mask.sum() == 0:\n",
    "                return self.user_mean[user_id]\n",
    "            \n",
    "            neighbor_ratings = item_ratings[rated_users_mask]\n",
    "            neighbor_similarities = similarities[rated_users_mask]\n",
    "            \n",
    "            # Remover similaridades negativas ou zero\n",
    "            positive_mask = neighbor_similarities > 0\n",
    "            if positive_mask.sum() < self.min_neighbors:\n",
    "                # Poucos vizinhos confi√°veis ‚Üí usar m√©dia do usu√°rio\n",
    "                return self.user_mean[user_id]\n",
    "            \n",
    "            neighbor_ratings = neighbor_ratings[positive_mask]\n",
    "            neighbor_similarities = neighbor_similarities[positive_mask]\n",
    "            \n",
    "            # Pegar top-k vizinhos\n",
    "            if len(neighbor_similarities) > self.k_neighbors:\n",
    "                top_k_idx = np.argsort(neighbor_similarities)[-self.k_neighbors:]\n",
    "                neighbor_ratings = neighbor_ratings.iloc[top_k_idx]\n",
    "                neighbor_similarities = neighbor_similarities[top_k_idx]\n",
    "            \n",
    "            # Calcular predi√ß√£o ponderada\n",
    "            total_similarity = neighbor_similarities.sum()\n",
    "            \n",
    "            if total_similarity == 0:\n",
    "                prediction = self.user_mean[user_id]\n",
    "            else:\n",
    "                prediction = np.average(neighbor_ratings, weights=neighbor_similarities)\n",
    "            \n",
    "            # VALIDA√á√ÉO FINAL: Verificar se predi√ß√£o √© v√°lida\n",
    "            if np.isnan(prediction) or np.isinf(prediction):\n",
    "                self.problem_predictions.append({\n",
    "                    'user_id': user_id,\n",
    "                    'item_id': item_id,\n",
    "                    'prediction': prediction,\n",
    "                    'fallback': self.user_mean[user_id]\n",
    "                })\n",
    "                return self.user_mean[user_id]\n",
    "            \n",
    "            # Limitar predi√ß√£o ao range v√°lido (ex: 1-5 para MovieLens)\n",
    "            min_rating = 1.0\n",
    "            max_rating = 5.0\n",
    "            prediction = np.clip(prediction, min_rating, max_rating)\n",
    "            \n",
    "            return float(prediction)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Qualquer erro ‚Üí fallback seguro\n",
    "            print(f\"   ‚ö†Ô∏è Erro na predi√ß√£o: {e}\")\n",
    "            return self.user_mean[user_id]\n",
    "    \n",
    "    def recommend(self, user_id: int, n: int = 5) -> list[int]:\n",
    "        \"\"\"Retorna top-N recomenda√ß√µes\"\"\"\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return []\n",
    "        \n",
    "        user_ratings = self.user_item_matrix.loc[user_id]\n",
    "        unrated_items = user_ratings[user_ratings.isna()].index\n",
    "        \n",
    "        predictions = []\n",
    "        for item_id in unrated_items:\n",
    "            pred_rating = self.predict(user_id, item_id)\n",
    "            predictions.append((item_id, pred_rating))\n",
    "        \n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [item_id for item_id, _ in predictions[:n]]\n",
    "    \n",
    "    def evaluate(self, test_df: pd.DataFrame, verbose: bool = True) -> dict:\n",
    "        \"\"\"Avalia modelo com diagn√≥stico detalhado\"\"\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"   Avaliando modelo no conjunto de teste...\")\n",
    "        \n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        invalid_count = 0\n",
    "        \n",
    "        for idx, row in test_df.iterrows():\n",
    "            pred = self.predict(row['user_id'], row['item_id'])\n",
    "            \n",
    "            # Verificar validade da predi√ß√£o\n",
    "            if np.isnan(pred) or np.isinf(pred):\n",
    "                invalid_count += 1\n",
    "                pred = self.global_mean\n",
    "            \n",
    "            predictions.append(pred)\n",
    "            actuals.append(row['rating'])\n",
    "            \n",
    "            if verbose and (idx + 1) % 5000 == 0:\n",
    "                print(f\"      Progresso: {idx+1}/{len(test_df)} predi√ß√µes\")\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "        mae = mean_absolute_error(actuals, predictions)\n",
    "        \n",
    "        # Diagn√≥stico adicional\n",
    "        predictions_array = np.array(predictions)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n   üîç Diagn√≥stico das predi√ß√µes:\")\n",
    "            print(f\"      Predi√ß√µes inv√°lidas: {invalid_count} ({invalid_count/len(predictions)*100:.2f}%)\")\n",
    "            print(f\"      Predi√ß√µes m√≠nima: {predictions_array.min():.2f}\")\n",
    "            print(f\"      Predi√ß√µes m√°xima: {predictions_array.max():.2f}\")\n",
    "            print(f\"      Predi√ß√µes m√©dia: {predictions_array.mean():.2f}\")\n",
    "            print(f\"      Predi√ß√µes std: {predictions_array.std():.2f}\")\n",
    "        \n",
    "        return {\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'invalid_predictions': invalid_count,\n",
    "            'predictions_stats': {\n",
    "                'min': float(predictions_array.min()),\n",
    "                'max': float(predictions_array.max()),\n",
    "                'mean': float(predictions_array.mean()),\n",
    "                'std': float(predictions_array.std())\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Treinar modelo\n",
    "cf_model = UserBasedCF(k_neighbors=30)\n",
    "cf_model.fit(train_df)\n",
    "\n",
    "# Avaliar\n",
    "cf_metrics = cf_model.evaluate(test_df)\n",
    "print(f\"\\nüìä M√©tricas no teste:\")\n",
    "print(f\"   RMSE: {cf_metrics['RMSE']:.4f}\")\n",
    "print(f\"   MAE: {cf_metrics['MAE']:.4f}\")\n",
    "\n",
    "# Compara√ß√£o com baseline\n",
    "print(f\"\\nüìà Melhoria sobre baseline:\")\n",
    "print(f\"   RMSE: {(1 - cf_metrics['RMSE']/baseline_metrics['RMSE'])*100:+.2f}%\")\n",
    "print(f\"   MAE: {(1 - cf_metrics['MAE']/baseline_metrics['MAE'])*100:+.2f}%\")\n",
    "\n",
    "# Salvar modelo\n",
    "with open('../models/collaborative_filtering_model.pkl', 'wb') as f:\n",
    "    pickle.dump(cf_model, f)\n",
    "print(\"üíæ Modelo salvo: ../models/collaborative_filtering_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd5ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
